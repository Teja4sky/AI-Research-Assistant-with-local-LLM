# AI-Research-Assistant-with-local-LLM
A locally powered AI Research Assistant built using Streamlit and Ollama (Llama 3.1) with semantic highlighting, PDF analysis, and offline research capabilities.
